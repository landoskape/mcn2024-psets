{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "B = 100 # Batch size\n",
    "D = 10 # Input dimensions\n",
    "N = 2 # Number of recurrent neurons\n",
    "T = 20 # Time steps per trial\n",
    "sigma = 0.1  # Noise amplitude\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 400\n",
    "num_contexts = 2\n",
    "\n",
    "task = tasks.VarGoNogo(D, T, sigma)\n",
    "start_integration = task.decision_start_time()\n",
    "\n",
    "# Create network\n",
    "net = models.SpikingRNN(task.input_dimensionality(), N, 2, synaptic=True)\n",
    "\n",
    "# Loss function and optimizer\n",
    "def loss_function(outputs, labels, spks, alpha=1.0):\n",
    "    target_loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "    spike_loss = 0.1 * torch.sum(spks, dim=2)\n",
    "    return target_loss + alpha * torch.mean(spike_loss)\n",
    "   \n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-2)\n",
    "\n",
    "\n",
    "save_accuracy = torch.zeros(num_epochs)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    X, labels, params = task.generate_data(B, T)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs, spks, syns, mems = net(X, start_integration=start_integration)\n",
    "    loss = loss_function(outputs, labels, spks, alpha=1.0)\n",
    "    # loss = criterion(outputs, labels)  # Use only the last time step for loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    choice = torch.argmax(outputs, dim=1)\n",
    "    accuracy = torch.sum(choice == labels).item() / B * 100\n",
    "    save_accuracy[epoch] = accuracy\n",
    "    \n",
    "    if (epoch + 1) % (num_epochs // 10) == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "X, labels, params = task.generate_data(B, T)\n",
    "outputs, spks, syns, mems = net(X, start_integration=start_integration)\n",
    "choice = torch.argmax(outputs, dim=1)\n",
    "print(f'Failures: Choice - Labels - EmpiricalS')\n",
    "errors = torch.stack((choice, labels), dim=1)[choice != labels]\n",
    "print(errors)\n",
    "print(f'Accuracy: {torch.sum(choice == labels).item() / B * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
